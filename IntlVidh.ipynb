{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#так будет инициализация\n",
    "for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "      elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "      elif isinstance(m, nn.Linear):\n",
    "        init.kaiming_normal(m.weight)\n",
    "        m.bias.data.zero_() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from group_norm  import GroupNorm2d #отсюда итпорт https://github.com/chengyangfu/pytorch-groupnormalization\n",
    "#https://pytorch.org/docs/stable/nn.html\n",
    "def norm2d(planes, num_channels_per_group=32):\n",
    "    print(\"num_channels_per_group:{}\".format(num_channels_per_group))\n",
    "    if num_channels_per_group > 0:\n",
    "        return GroupNorm2d(planes, num_channels_per_group, affine=True,\n",
    "                           track_running_stats=False)\n",
    "    else:\n",
    "        return nn.BatchNorm2d(planes)\n",
    "\n",
    "\n",
    "Modda1 =  nn.Sequential(\n",
    "          nn.Conv2d(3,32,3,padding=2,bias=True)#попробовать elasticnet regularization. что не так с l2\n",
    "          nn.GroupNorm(3, 32)\n",
    "          nn.LeakyReLU()\n",
    "          nn.Conv2d(32,32,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(3, 32)# https://github.com/chengyangfu/pytorch-groupnormalization это хуячь #вроде так\n",
    "          nn.LeakyReLU()\n",
    "          nn.MaxPool2d(2) #даунсемплинг 75 #попробовать fractional max-pooling\n",
    "          nn.Conv2d(32,64,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(4, 64)\n",
    "          nn.LeakyReLU()\n",
    "          nn.Conv2d(64,64,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(4, 64)\n",
    "          nn.LeakyReLU()\n",
    "          nn.MaxPool2d(3)#даунсемплинг 25\n",
    "          nn.Conv2d(64,256,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(4, 256)\n",
    "          nn.LeakyReLU()\n",
    "          nn.Conv2d(256,256,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(4, 256)\n",
    "          nn.LeakyReLU()\n",
    "          nn.Conv2d(256,256,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(4, 256))\n",
    "          nn.LeakyReLU()\n",
    "          nn.Conv2d(256,256,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(4, 256)\n",
    "          nn.LeakyReLU()\n",
    "          nn.MaxPool2d(5)#даунсемплинг 5\n",
    "          nn.Conv2d(256,512,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(8, 512) \n",
    "          nn.LeakyReLU()\n",
    "          nn.Conv2d(512,512,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(4, 512)\n",
    "          nn.LeakyReLU()\n",
    "          nn.Conv2d(512,512,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(2, 512)\n",
    "          nn.LeakyReLU()\n",
    "          nn.Conv2d(512,512,3,padding=2,bias=True)\n",
    "          nn.GroupNorm(2, 512)\n",
    "          nn.LeakyReLU()\n",
    "          nn.Linear(in_features=5*5*512, out_features=10, bias=True) \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pre-trained models (коричневая тетрадь, как хэндлить относительно схожести и количества данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model zoos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#в model ensembles/snapshots u can use dropout/stochastic depthdsfvlj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "densenet = models.densenet161(pretrained=True)\n",
    "inception = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "concatenated = concatenate([Modda1, vgg16,densenet, inception])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Dense(1, activation='softmax', name='output_layer')(concatenated)\n",
    "\n",
    "merged_model = Model([150, 150], out)\n",
    "merged_model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights.h5', monitor='val_acc',\n",
    "save_best_only=True, verbose=2)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "merged_model.fit([x1, x2], y=y, batch_size=384, epochs=200,\n",
    "             verbose=1, validation_split=0.1, shuffle=True, \n",
    "callbacks=[early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
